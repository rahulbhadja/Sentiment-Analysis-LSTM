{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYF94Xq3c3BQ",
        "outputId": "dbb12b86-407f-4c38-d3a0-6606ee136d52",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hs-u6Sk7gzXC"
      },
      "source": [
        "import pandas as pd    # to load dataset\n",
        "import numpy as np     # for mathematic equation\n",
        "from nltk.corpus import stopwords   # to get collection of stopwords\n",
        "from sklearn.model_selection import train_test_split       # for splitting dataset\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer  # to encode text to int\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences   # to do padding or truncating\n",
        "from tensorflow.keras.models import Sequential     # the model\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense # layers of the architecture\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint   # save model\n",
        "from tensorflow.keras.models import load_model   # load saved model\n",
        "import re"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYGN2KqYg64S",
        "outputId": "a5143963-3774-4b27-f65b-eb3662c76c82",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        }
      },
      "source": [
        "data = pd.read_csv('/content/drive/My Drive/archive/IMDB Dataset.csv')\n",
        "\n",
        "print(data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                                  review sentiment\n",
            "0      One of the other reviewers has mentioned that ...  positive\n",
            "1      A wonderful little production. <br /><br />The...  positive\n",
            "2      I thought this was a wonderful way to spend ti...  positive\n",
            "3      Basically there's a family where a little boy ...  negative\n",
            "4      Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
            "...                                                  ...       ...\n",
            "49995  I thought this movie did a down right good job...  positive\n",
            "49996  Bad plot, bad dialogue, bad acting, idiotic di...  negative\n",
            "49997  I am a Catholic taught in parochial elementary...  negative\n",
            "49998  I'm going to have to disagree with the previou...  negative\n",
            "49999  No one expects the Star Trek movies to be high...  negative\n",
            "\n",
            "[50000 rows x 2 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "klOCRYFNg_ha"
      },
      "source": [
        "english_stops = set(stopwords.words('english'))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "joRcIzADhCU0",
        "outputId": "6491e97f-98d0-4330-9ac5-eb1c8bda4025",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        }
      },
      "source": [
        "def load_dataset():\n",
        "    df = pd.read_csv('/content/drive/My Drive/archive/IMDB Dataset.csv')\n",
        "    x_data = df['review']       # Reviews/Input\n",
        "    y_data = df['sentiment']    # Sentiment/Output\n",
        "\n",
        "    # PRE-PROCESS REVIEW\n",
        "    x_data = x_data.replace({'<.*?>': ''}, regex = True)          # remove html tag\n",
        "    x_data = x_data.replace({'[^A-Za-z]': ' '}, regex = True)     # remove non alphabet\n",
        "    x_data = x_data.apply(lambda review: [w for w in review.split() if w not in english_stops])  # remove stop words\n",
        "    x_data = x_data.apply(lambda review: [w.lower() for w in review])   # lower case\n",
        "    \n",
        "    # ENCODE SENTIMENT -> 0 & 1\n",
        "    y_data = y_data.replace('positive', 1)\n",
        "    y_data = y_data.replace('negative', 0)\n",
        "\n",
        "    return x_data, y_data\n",
        "\n",
        "x_data, y_data = load_dataset()\n",
        "\n",
        "print('Reviews')\n",
        "print(x_data, '\\n')\n",
        "print('Sentiment')\n",
        "print(y_data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reviews\n",
            "0        [one, reviewers, mentioned, watching, oz, epis...\n",
            "1        [a, wonderful, little, production, the, filmin...\n",
            "2        [i, thought, wonderful, way, spend, time, hot,...\n",
            "3        [basically, family, little, boy, jake, thinks,...\n",
            "4        [petter, mattei, love, time, money, visually, ...\n",
            "                               ...                        \n",
            "49995    [i, thought, movie, right, good, job, it, crea...\n",
            "49996    [bad, plot, bad, dialogue, bad, acting, idioti...\n",
            "49997    [i, catholic, taught, parochial, elementary, s...\n",
            "49998    [i, going, disagree, previous, comment, side, ...\n",
            "49999    [no, one, expects, star, trek, movies, high, a...\n",
            "Name: review, Length: 50000, dtype: object \n",
            "\n",
            "Sentiment\n",
            "0        1\n",
            "1        1\n",
            "2        1\n",
            "3        0\n",
            "4        1\n",
            "        ..\n",
            "49995    1\n",
            "49996    0\n",
            "49997    0\n",
            "49998    0\n",
            "49999    0\n",
            "Name: sentiment, Length: 50000, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Deq25V7hFqL",
        "outputId": "ef0f2389-26f6-423b-ead8-e5a4865976f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 907
        }
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size = 0.2)\n",
        "\n",
        "print('Train Set')\n",
        "print(x_train, '\\n')\n",
        "print(x_test, '\\n')\n",
        "print('Test Set')\n",
        "print(y_train, '\\n')\n",
        "print(y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Set\n",
            "29729    [contains, spoilersthis, peter, watkins, film,...\n",
            "8640     [first, i, played, second, monkey, island, gam...\n",
            "6569     [i, heard, first, oceans, movie, sequels, begi...\n",
            "2209     [this, good, plot, concept, poor, film, the, a...\n",
            "34856    [national, lampoon, goes, movies, absolutely, ...\n",
            "                               ...                        \n",
            "49814    [the, gates, hell, opened, spit, film, closed,...\n",
            "13693    [this, movie, poorly, written, hard, follow, f...\n",
            "10085    [i, could, even, bring, watch, movie, end, i, ...\n",
            "44681    [growing, joe, strummer, hero, mine, even, i, ...\n",
            "9661     [quit, ahead, phrase, never, learn, typical, h...\n",
            "Name: review, Length: 40000, dtype: object \n",
            "\n",
            "35662    [this, i, call, growth, movie, every, characte...\n",
            "11974    [real, hoot, unintentionally, sidney, portier,...\n",
            "13334    [the, acting, pretty, cheesy, people, area, de...\n",
            "7580     [this, movie, seemed, like, going, better, end...\n",
            "45121    [this, movie, nothing, religious, tract, promo...\n",
            "                               ...                        \n",
            "5833     [i, recent, spectator, experience, the, perfec...\n",
            "426      [a, rather, silly, little, film, may, love, al...\n",
            "17753    [house, calls, amusing, comedy, widowed, docto...\n",
            "35580    [it, good, movie, plan, watch, lots, landscape...\n",
            "39359    [have, ever, wondered, like, feel, free, i, su...\n",
            "Name: review, Length: 10000, dtype: object \n",
            "\n",
            "Test Set\n",
            "29729    1\n",
            "8640     1\n",
            "6569     1\n",
            "2209     0\n",
            "34856    0\n",
            "        ..\n",
            "49814    0\n",
            "13693    0\n",
            "10085    0\n",
            "44681    0\n",
            "9661     0\n",
            "Name: sentiment, Length: 40000, dtype: int64 \n",
            "\n",
            "35662    1\n",
            "11974    0\n",
            "13334    1\n",
            "7580     0\n",
            "45121    0\n",
            "        ..\n",
            "5833     0\n",
            "426      1\n",
            "17753    1\n",
            "35580    0\n",
            "39359    1\n",
            "Name: sentiment, Length: 10000, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_W8FC7LlhPtz"
      },
      "source": [
        "def get_max_length():\n",
        "    review_length = []\n",
        "    for review in x_train:\n",
        "        review_length.append(len(review))\n",
        "\n",
        "    return int(np.ceil(np.mean(review_length)))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EbOFpbhIhSH9",
        "outputId": "2f63a01e-001c-4bea-8755-6eafbb84fd72",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        }
      },
      "source": [
        "# ENCODE REVIEW\n",
        "token = Tokenizer(lower=False)    # no need lower, because already lowered the data in load_data()\n",
        "token.fit_on_texts(x_train)\n",
        "x_train = token.texts_to_sequences(x_train)\n",
        "x_test = token.texts_to_sequences(x_test)\n",
        "\n",
        "max_length = get_max_length()\n",
        "\n",
        "x_train = pad_sequences(x_train, maxlen=max_length, padding='post', truncating='post')\n",
        "x_test = pad_sequences(x_test, maxlen=max_length, padding='post', truncating='post')\n",
        "\n",
        "total_words = len(token.word_index) + 1   # add 1 because of 0 padding\n",
        "\n",
        "print('Encoded X Train\\n', x_train, '\\n')\n",
        "print('Encoded X Test\\n', x_test, '\\n')\n",
        "print('Maximum review length: ', max_length)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Encoded X Train\n",
            " [[ 1274 30177   716 ...    60    46 19425]\n",
            " [   23     1   161 ...     0     0     0]\n",
            " [    1   462    23 ...     0     0     0]\n",
            " ...\n",
            " [    1    27    11 ...     0     0     0]\n",
            " [ 1795   841 24090 ...  4878  3502 24090]\n",
            " [ 4978  1352  4619 ...    66    24 12016]] \n",
            "\n",
            "Encoded X Test\n",
            " [[   8    1  574 ...    0    0    0]\n",
            " [  64 5380 3432 ...    0    0    0]\n",
            " [   2   43   88 ...    0    0    0]\n",
            " ...\n",
            " [ 228 1667 1054 ...    0    0    0]\n",
            " [   7    9    3 ...    0    0    0]\n",
            " [2015   51 4123 ...    0    0    0]] \n",
            "\n",
            "Maximum review length:  130\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rKSq3Tt9hVgK",
        "outputId": "7c1b8a06-a169-4646-f5e7-38c7d00949b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "EMBED_DIM = 32\n",
        "LSTM_OUT = 64\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(total_words, EMBED_DIM, input_length = max_length))\n",
        "model.add(LSTM(LSTM_OUT))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 130, 32)           2954528   \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 64)                24832     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 2,979,425\n",
            "Trainable params: 2,979,425\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7mb99Q8ghZ3q"
      },
      "source": [
        "checkpoint = ModelCheckpoint(\n",
        "    '/content/drive/My Drive/archive/lstm/LSTM.h5',\n",
        "    monitor='accuracy',\n",
        "    save_best_only=True,\n",
        "    verbose=1\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "toALnNOlhgvo",
        "outputId": "261aeb49-3cb6-4ca6-94fe-7c917b3c6fed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        }
      },
      "source": [
        "model.fit(x_train, y_train, batch_size = 128, epochs = 5, callbacks=[checkpoint])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "313/313 [==============================] - ETA: 0s - loss: 0.4748 - accuracy: 0.7481\n",
            "Epoch 00001: accuracy improved from -inf to 0.74810, saving model to /content/drive/My Drive/archive/lstm/LSTM.h5\n",
            "313/313 [==============================] - 18s 57ms/step - loss: 0.4748 - accuracy: 0.7481\n",
            "Epoch 2/5\n",
            "313/313 [==============================] - ETA: 0s - loss: 0.2129 - accuracy: 0.9240\n",
            "Epoch 00002: accuracy improved from 0.74810 to 0.92395, saving model to /content/drive/My Drive/archive/lstm/LSTM.h5\n",
            "313/313 [==============================] - 18s 57ms/step - loss: 0.2129 - accuracy: 0.9240\n",
            "Epoch 3/5\n",
            "313/313 [==============================] - ETA: 0s - loss: 0.1301 - accuracy: 0.9591\n",
            "Epoch 00003: accuracy improved from 0.92395 to 0.95907, saving model to /content/drive/My Drive/archive/lstm/LSTM.h5\n",
            "313/313 [==============================] - 18s 56ms/step - loss: 0.1301 - accuracy: 0.9591\n",
            "Epoch 4/5\n",
            "312/313 [============================>.] - ETA: 0s - loss: 0.0782 - accuracy: 0.9777\n",
            "Epoch 00004: accuracy improved from 0.95907 to 0.97768, saving model to /content/drive/My Drive/archive/lstm/LSTM.h5\n",
            "313/313 [==============================] - 18s 57ms/step - loss: 0.0783 - accuracy: 0.9777\n",
            "Epoch 5/5\n",
            "313/313 [==============================] - ETA: 0s - loss: 0.0525 - accuracy: 0.9864\n",
            "Epoch 00005: accuracy improved from 0.97768 to 0.98637, saving model to /content/drive/My Drive/archive/lstm/LSTM.h5\n",
            "313/313 [==============================] - 18s 56ms/step - loss: 0.0525 - accuracy: 0.9864\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7ff687bf9da0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g6AeT7UjhisB",
        "outputId": "671d6b45-1872-4f02-c8c9-9e84899737c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "y_pred = model.predict_classes(x_test, batch_size = 128)\n",
        "\n",
        "true = 0\n",
        "for i, y in enumerate(y_test):\n",
        "    if y == y_pred[i]:\n",
        "        true += 1\n",
        "\n",
        "print('Correct Prediction: {}'.format(true))\n",
        "print('Wrong Prediction: {}'.format(len(y_pred) - true))\n",
        "print('Accuracy: {}'.format(true/len(y_pred)*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Correct Prediction: 8669\n",
            "Wrong Prediction: 1331\n",
            "Accuracy: 86.69\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}